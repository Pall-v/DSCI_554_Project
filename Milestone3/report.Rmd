---
title: "Milestone 3 - Report"
date: "Date: 2019/04/22"  
author: "Authors: Patrick Tung, Paul Vial, and  Mengda (Albert) Yu"
output:
   github_document:
     toc: true
     toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(library(MASS))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(lmtest))
suppressPackageStartupMessages(library(car))
```

```{r prepare data, echo=FALSE}
# Read data
data <- suppressMessages(read_csv("../Milestone2/data/data.csv", skip = 2))

# Select data
data <-  
  data %>%
  dplyr::select(18:22)

# Rename columns
names(data) <- c("sex", "math_skill", "friend_with_prog", "prog_exp", "difficulty")

# factorize variable in the data
clean_data <-
  data %>%
  mutate(sex = as_factor(sex),
         math_skill = factor(math_skill,
                                levels=c("Below Average",
                                         "Average",
                                         "Above Average"), ordered=FALSE),
         friend_with_prog = as_factor(friend_with_prog),
         prog_exp = factor(prog_exp,
                              levels=c("None",
                                       "Less than 100 hours",
                                       "Less than 1000 hours",
                                       "More than 1000 hours"), ordered=FALSE),
         difficulty = factor(difficulty,
                                levels=c("Easier than average",
                                         "Average",
                                         "More difficult than average"),
                                ordered=TRUE)
  )

```   

# 1.0 Introduction

As the Master of Data science program is soon to end, we all like to reflect on the courses we have taken. Some courses we took were difficult and some were relatively easy, but the true question is, how was this affected by our prior experience. DSCI 512 is a programming and algorithms course in the MDS program at UBC which introduces fundamental algorithms such as sorting and searching, as well as data structures. This project is to analyze whether the level of programming experience prior to the MDS program affects an MDS student's self-perceived difficulty of DSCI 512 materials.

Question: Does their level of programming experience prior to the MDS program influence a person's self-perceived difficulty of DSCI 512 (Algorithms and Data Structures)?

We began with defining a null hypothesis and alternative hypothesis, as shown below.

> **Null hypothesis:** The level of programming experience prior to the MDS program does not influence a person's self-perceived difficulty regarding DSCI 512.

> **Alternative hypothesis:** The level of programming experience prior to the MDS program influences a person's self-perceived difficulty regarding DSCI 512.

After extensive brainstorming, we decided that the variables we believe that are important are:

- Previous programming experience
- Sex
- Mathematics skill level
- Whether or not a student has friends or family with programming experience

# 2.0 Data description

To gather the data, we created a survey and collected 56 observations from our fellow MDS students, DSCI 554 TAs, and lab instructor for self-perceived difficulty of the DSCI 512 course.


| Variable | Name | Type | Description |
|:---:|:---:|:---:|:---:|
| Confounder | `sex` | categorical | Female or Male |
| Confounder | `math_skill` | categorical | Self-reported Math skills (Below average, Average, Above average) |
| Confounder | `friend_with_prog` |  category | Friends who have jobs associated with programming (No, Yes)|
| Main Covariate | `prog_exp` | categorical | Previous programming experience prior to the MDS in hour (None, Less than 100 hours, Less than 1000 hours, More than 1000 hours) |
| Outcome | `difficulty` | ordinal | Self-perceived difficulty (Easier than average, Average, More difficult than average) |

*Table 1: Surveyed Variables*



```{r summary table 1, echo=FALSE, fig.align='center'}
# cross classication counts for difficulty by sex
kable(prop.table(table(clean_data$difficulty, clean_data$sex)))
```

*Table 2: Cross classication proportions for difficulty by sex*



```{r summary table 2, echo=FALSE, fig.align='center'}
# cross classication counts for difficulty by math_skill
kable(prop.table(table(clean_data$difficulty, clean_data$math_skill)))
```

*Table 3: Cross classication proportions for difficulty by math skills*



```{r summary table 3, echo=FALSE, fig.align='center'}
# cross classication counts for difficulty by friend_with_prog
kable(prop.table(table(clean_data$difficulty, clean_data$friend_with_prog)))
```

*Table 4: Cross classication proportions for difficulty by friends or family with programming experience*



```{r summary table 4, echo=FALSE, fig.align='center'}
# cross classication counts for difficulty by prog_exp
kable(prop.table(table(clean_data$difficulty, clean_data$prog_exp)))
```

*Table 5: Cross classication proportions for difficulty by programming experience*


# 3.0 Key EDA

First, we did some preliminary investigations to understand the data and discover important patterns.

```{r Figure1, echo=FALSE,fig.align='center'}
clean_data %>% ggplot(aes(prog_exp, difficulty)) +
  geom_bin2d() +
  theme_bw() +
  labs(y = "Self-perceived ifficulty",
       x = "Programming Experience",
       title = "Heatmap of Programming Experience vs. Difficulty") +
  theme(plot.title = element_text(size = 13, face = "bold", hjust = 0.5)) +
  coord_fixed() +
  scale_x_discrete(
    labels = function(difficulty)
      str_wrap(difficulty, width = 14)
  ) +
  scale_fill_continuous(breaks = c(1, 5, 9))
```

*Figure 1.*

It can be seen that the number of students who have been experiencing a harder time in DSCI 512 is greater than the number of students who found the course easier than average.

```{r Figure2, echo=FALSE, fig.align='center'}
clean_data %>%
  ggplot() +
  theme_bw() +
  labs(y = "Self-perceived ifficulty",
       x = "Programming Experience",
       title = "Heatmap of Programming Experience vs. Difficulty") +
  theme(plot.title = element_text(size = 13, face = "bold", hjust = 0.5)) +
  geom_bar(aes(difficulty)) +
  facet_wrap(~prog_exp)
```

*Figure 2.*

The group without programming experience had the greatest proportion of people that found the course to be difficult.  It makes sense that if students have no programming experiences, they are more likely to struggle with assignments and tests. It is also interesting that the most commonly reported level of difficulty was "Average" across the three other groups (less than 100, less than 1000 hours, More than 1000 hours), and that relatively few students found the course to be more difficult or less difficult than average.


```{r figure3, echo=FALSE, fig.align='center'}
clean_data %>%
  ggplot() +
  theme_bw() +
  labs(x = "Self-preceived difficulty",
    y = "Ratio",
    title = "Self-perceived difficulty vs. Sex") +
  theme(plot.title = element_text(size = 13, face = "bold", hjust = 0.5)) +
  geom_bar(aes(x = difficulty, fill=sex), position = "fill")
```

*Figure 3.*

Most male students reported average difficulty. The number of female students who felt the course was easy is greater than the number of male students who felt that way.


```{r figure4, echo=FALSE, fig.align='center'}
clean_data %>%
  ggplot() +
  theme_bw() +
  labs(x = "Self-preceived difficulty",
    # y = "y",
    title = "Self-perceived difficulty vs. math skill") +
  theme(plot.title = element_text(size = 13, face = "bold", hjust = 0.5)) +
  geom_bar(aes(x = difficulty, fill = math_skill), position = "dodge")
```

*Figure 4.*

In this figure, we observe that most of the students who have proficiency in math felt that the difficulty of DSCI 512 was average. It seems that math skills do not affect self-perceived difficulty.

```{r figure5, echo=FALSE, fig.align='center'}
clean_data %>%
  ggplot() +
  theme_bw() +
  labs(x = "Friend with programming experience",
    y = "ratio",
    title = "Self-perceived difficulty vs. friend with programming experience") +
  theme(plot.title = element_text(size = 13, face = "bold", hjust = 0.5)) +
  geom_bar(aes(x = friend_with_prog, fill = difficulty), position = "fill")
```

*Figure 5.*

It is interesting to note that the students who have no friends or family with programming experience are more likely to experience difficulty. If a student has friends with programming experience, he/she tends to feel the difficulty of the course is average.


# 4.0 Analysis

To analyze our data, we implemented two different methods of testing: (1) Ordinal Regression Test and (2) Likelihood Ratio Test with Ordinal Regression.

## Method 1 - Ordinal Regression Test

We decided to apply ordinal regression to test whether the main exposure `prog_exp` has a significant impact on our outcome `difficulty`. The orginal regression is used to facilitate the interaction of dependent variables (having multiple ordered levels) with one or more independent variables. 

```{r}
m <- polr(difficulty~sex+math_skill+friend_with_prog+prog_exp, data=clean_data, Hess=TRUE)
summary(m)
```

SE, coef, t-value......

AIC -> smaller -> better


### 2. Calculate p-Value, CI, Odds ratio

```{r}
# p-values
ctable <- coef(summary(m))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
ctable <- cbind(ctable, "p value" = p)
ctable
```

```{r}
# CI
ci <- confint(m)
```

```{r}
# OR and Ci
exp(cbind(OR = coef(m), ci))
```

```{r}
Anova(m, type = 3)
```

## Method 2 - Likelihood Ratio Test with Ordinal Logistic Regression

Here we compare the fit of several different models.  We have forgone any multiple comparison corrections due to the high p-values resulting from **all** of the models below.  If any of these models had p-values less than 0.05, we would have controlled the family-wise error rate via a Bonferroni correction.

First, we compare the null model to the model from Method 1 above:

```{r olr.M0}
#Null model, no predictors
olr.M0 <- polr(difficulty~1, data=clean_data)   
```


```{r olr.M1}
#Full model
olr.M1 <- polr(difficulty~sex+math_skill+friend_with_prog+prog_exp, data=clean_data)
```


```{r}
#Are all variables good predictors?
lrtest(olr.M1, olr.M0)
```

Based on the p-value, this model does not provide a better fit than the null model.  Next, we try a model using only our main independent variable, `prog_exp`:

```{r olr.M2}
# Reduced model, with our main variable
olr.M2 <- polr(difficulty~prog_exp, data=clean_data)
```


```{r}
# How does the model without any confounding variables perform?
lrtest(olr.M2, olr.M0)
```

This model provides an even worse fit compared to the null model.  

Lastly, we try modelling an interaction between `friend_with_prog`, and `prog_exp`.  The rationale here is that the effect of having a friend or family member with programming experience may vary based on personal programming experience.  For example, a student with more than 1000 hours of programming experience may not benefit from having a friend or family member with programming experience because they already have the programming that the friend or family member might otherwise help them with.  On the other hand, a student with no programming experience probably stands to benefit far more if they have a friend or family member who can help them with coding.

```{r olr.M3}
# Modeling a possible interaction 
olr.M3 <- polr(difficulty~friend_with_prog*prog_exp, data=clean_data)
```


```{r}
# How does the interaction model perform?
lrtest(olr.M3, olr.M0)
```

Again, this does not yeild a better fit than the null model.

```{r olr.M4}
# TBD: Shoud we try this?
olr.M4 <- polr(difficulty~sex+math_skill+friend_with_prog*prog_exp, data=clean_data)

```


```{r}
#Are all variables good predictors?
lrtest(olr.M4, olr.M0)
```


# 5.0 Discussion

## 5.1 Findings
  1. Discussing the results and findings of your survey and analysis of the survey data.


## 5.2 Survey design
Discussing your survey/study design, specifically:

1. what did you do well to make this study as causal as possible?

We put a lot of thought into which variables to include as potential confounders.  Spending the proper amount of time on this before distributing the survey helped ensure that we did not realize additional potential confounders during our analysis when it would be too late to gather data to control for them.  This diligence helped our end goal of reaching a conclusion free of spurious findings.

2. what was not done well and how did that effect your studies conclusions?

One of the biggest problems that we discovered after performing the analysis is that the amount of data we collected is simply not enough to make conclusive claims. Perhaps it would have been helpful if we decided to collect data from previous cohorts of the MDS program. It might also be better if we continued our research to allow future MDS cohorts to reflect and take the survey. 

Another issue of our survey is that the level of "self-reported" information is very subjective. An "Average" difficulty might mean something different to two different students. Therefore, it is quite difficult to evaluate the results of our research.

3. what would you do differently next time to improve your survey/study design and why?

Originally when we were designing our survey, we thought it was very logical to make our variables categorical and ordinal, even our response variable (i.e. self-perceived difficulty of DSCI 512). However, while we were performing analyses and tests with our data, we realized that because our variables were not numerical, we lost a lot of flexibility with our analysis. If, for example, our response variable was numerical, we could have performed more tests such as ANOVA. Furthermore, if we found that numerical data does not work with our analysis, we could have binned them to become categorical. We feel that only using categorical data limited our ability to perform different analysis, and if we were to perform similar research in the future, this is definitely something we would change.

---


- Your target audience is other Data Scientists who are not familiar with your project.
- Clearly introduce the survey topic and question you were interested in answering.
- Link to your study's data and code in the methods section of your report.
- Include effective visualizations and/or tables that help communicate your findings.
- Your discussion should have 2 key focuses:
  1. Discussing the results and findings of your survey and analysis of the survey data.
  2. Discussing your survey/study design, specifically:
    - what did you do well to make this study as causal as possible?
    - what was not done well and how did that effect your studies conclusions?
    - what would you do differently next time to improve your survey/study design and why?
